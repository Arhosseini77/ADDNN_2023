
# Analysis and Design of Deep Neural Networks - Homework Submission

This repository contains homework submissions for the course "Analysis and Design of Deep Neural Networks," instructed by Dr. Ahmad Kalhor and Dr. Babak Arabi Najar. 
## Course Overview

The course delves into the intricacies of designing and analyzing deep neural networks, emphasizing two key concepts:
- **Separation Index (SI)** 
- **Smoothness Index (SMI)** 

## Repository Contents

#### Homework 1: Data Evaluation - Subset Selection and Feature Selection

In this section, you will find code that demonstrates techniques for evaluating and selecting subsets of data (Separation Index and Smoothness Index), as well as selecting features that are most relevant to the predictive models. The code includes examples of different feature selection methods to improve model accuracy and efficiency.

#### Homework 2: Model and Layer Evaluation

This part contains code for evaluating models and their layers. It includes scripts for testing model performance, analyzing layer outputs, and understanding how different layers contribute to the final predictions of the network.

#### Homework Extra: Feature Representation

An extra assignment that dives into feature representation techniques. Here, you'll find examples on how to effectively represent features in a way that enhances model learning and prediction accuracy.

#### Homework 3: Layer-wise Learning - Image Segmentation Network

This section focuses on layer-wise learning strategies. It includes code for implementing and training segmentation models, with a focus on understanding how learning can be optimized on a layer-wise basis.

#### Homework 4: Model Compressing

In this part, we explore model compression techniques to reduce the size of deep learning models without significantly compromising their performance. This is crucial for deploying models on devices with limited computational resources.

#### Homework 5: Metric Learning

This final section covers metric learning, focusing on triplet loss, contrastive loss,  Fisher Discriminant Contrastive Loss (FDT) loss, and  Fisher Discriminant triplet Loss(FCT). These techniques are essential for tasks that involve learning from relative comparisons between data points rather than absolute labels.

This repository includes:
- Code implementations of homework assignments.
- Jupyter notebooks with detailed explanations and results.


## Key Features

- Implementation of Separation Index and Smoothness Index found at [data_complexity_measures GitHub repository](https://github.com/Arhosseini77/data_complexity_measures).

## Environment and Dependencies

- **Python Version:** 3.10
- **PyTorch Version:** 2.1.0+cuda 12.1


## Acknowledgments

Special thanks to Dr. Ahmad Kalhor and Dr. Babak Arabi Najar for their invaluable guidance and instruction throughout the course.

---

